cpu-bind=MASK - dlcgpu01, task  0  0 [14211]: mask 0xfff00000fff0 set
+ CODE_DIR=/work/dlclarge2/ferreira-symreg/ScalingSymbolicRegression
++ scontrol show hostnames dlcgpu01
++ head -n 1
+ MASTER_ADDR=dlcgpu01
+ export MASTER_PORT=20073
+ MASTER_PORT=20073
+ export NUM_NODES=1
+ NUM_NODES=1
+ export GPUS_PER_NODE=1
+ GPUS_PER_NODE=1
+ export NUM_GPUS_PER_NODE=1
+ NUM_GPUS_PER_NODE=1
+ export NUM_GPUS=1
+ NUM_GPUS=1
+ echo 'INFO: number of nodes: 1'
INFO: number of nodes: 1
+ echo 'INFO: number of gpus per node: 1'
INFO: number of gpus per node: 1
+ echo 'INFO: number of gpus: 1'
INFO: number of gpus: 1
+ echo 'INFO: number of nnudes: 1'
INFO: number of nnudes: 1
+ ACCELERATE_CONFIG_FILE=/work/dlclarge2/ferreira-symreg/ScalingSymbolicRegression/scripts/accelerate.yaml
+ cat
+ cuda12.1
/var/spool/slurm/job12045301/slurm_script: line 51: cuda12.1: command not found
+ echo SLURM_PARTITION=dlcgpu01
SLURM_PARTITION=dlcgpu01
+ echo 'KISLURM Job'
KISLURM Job
+ source /home/ferreira/.miniconda/bin/activate symreg
++ _CONDA_ROOT=/home/ferreira/.miniconda
++ . /home/ferreira/.miniconda/etc/profile.d/conda.sh
+++ export CONDA_EXE=/home/ferreira/.miniconda/bin/conda
+++ CONDA_EXE=/home/ferreira/.miniconda/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/home/ferreira/.miniconda/bin/python
+++ CONDA_PYTHON_EXE=/home/ferreira/.miniconda/bin/python
+++ '[' -z x ']'
++ conda activate symreg
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate symreg
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate symreg
+++ /home/ferreira/.miniconda/bin/conda shell.posix activate symreg
++ ask_conda='PS1='\''(symreg) '\''
export PATH='\''/home/ferreira/.miniconda/envs/symreg/bin:/home/ferreira/bin:/usr/local/bin:/usr/sbin:/sbin:/usr/bin:/bin/home/ferreira/.miniconda/envs/minsim2/bin:/home/ferreira/.miniconda/condabin:/bin:/usr/bin:/usr/local/bin:/home/ferreira/.just:/home/ferreira/.poetry/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games'\''
export CONDA_SHLVL='\''3'\''
export CONDA_PROMPT_MODIFIER='\''(symreg) '\'''
++ eval 'PS1='\''(symreg) '\''
export PATH='\''/home/ferreira/.miniconda/envs/symreg/bin:/home/ferreira/bin:/usr/local/bin:/usr/sbin:/sbin:/usr/bin:/bin/home/ferreira/.miniconda/envs/minsim2/bin:/home/ferreira/.miniconda/condabin:/bin:/usr/bin:/usr/local/bin:/home/ferreira/.just:/home/ferreira/.poetry/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games'\''
export CONDA_SHLVL='\''3'\''
export CONDA_PROMPT_MODIFIER='\''(symreg) '\'''
+++ PS1='(symreg) '
+++ export PATH=/home/ferreira/.miniconda/envs/symreg/bin:/home/ferreira/bin:/usr/local/bin:/usr/sbin:/sbin:/usr/bin:/bin/home/ferreira/.miniconda/envs/minsim2/bin:/home/ferreira/.miniconda/condabin:/bin:/usr/bin:/usr/local/bin:/home/ferreira/.just:/home/ferreira/.poetry/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
+++ PATH=/home/ferreira/.miniconda/envs/symreg/bin:/home/ferreira/bin:/usr/local/bin:/usr/sbin:/sbin:/usr/bin:/bin/home/ferreira/.miniconda/envs/minsim2/bin:/home/ferreira/.miniconda/condabin:/bin:/usr/bin:/usr/local/bin:/home/ferreira/.just:/home/ferreira/.poetry/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
+++ export CONDA_SHLVL=3
+++ CONDA_SHLVL=3
+++ export 'CONDA_PROMPT_MODIFIER=(symreg) '
+++ CONDA_PROMPT_MODIFIER='(symreg) '
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ PYTHON_SCRIPT=/work/dlclarge2/ferreira-symreg/ScalingSymbolicRegression/train_gpr.py
+ (( i=0 ))
+ (( i<1 ))
+ cmd='srun -lN1 -n1 -r 0 accelerate launch         --config_file $ACCELERATE_CONFIG_FILE         --rdzv_conf "rdzv_backend=c10d,rdzv_endpoint=$MASTER_ADDR:$MASTER_PORT"         --main_process_ip $MASTER_ADDR         --main_process_port $MASTER_PORT         --machine_rank 0          $PYTHON_SCRIPT -c kislurm_config.yaml $@'
+ [[ 0 -lt 0 ]]
+ eval srun -lN1 -n1 -r 0 accelerate launch --config_file '$ACCELERATE_CONFIG_FILE' --rdzv_conf '"rdzv_backend=c10d,rdzv_endpoint=$MASTER_ADDR:$MASTER_PORT"' --main_process_ip '$MASTER_ADDR' --main_process_port '$MASTER_PORT' --machine_rank 0 '$PYTHON_SCRIPT' -c kislurm_config.yaml '$@'
++ srun -lN1 -n1 -r 0 accelerate launch --config_file /work/dlclarge2/ferreira-symreg/ScalingSymbolicRegression/scripts/accelerate.yaml --rdzv_conf rdzv_backend=c10d,rdzv_endpoint=dlcgpu01:20073 --main_process_ip dlcgpu01 --main_process_port 20073 --machine_rank 0 /work/dlclarge2/ferreira-symreg/ScalingSymbolicRegression/train_gpr.py -c kislurm_config.yaml
0: [29/10/2024 18:39:06][rank 0][INFO][__main__] - #### Load logger on rank 0
0: [29/10/2024 18:39:06][rank 0][INFO][__main__] - ########  Accelerate: world size 1 - rank 0
0: [29/10/2024 18:39:06][rank 0][INFO][__main__] - [1m######################################################[0m
0: [29/10/2024 18:39:06][rank 0][INFO][__main__] - [1m########          START   TRAINING          ##########[0m
0: [29/10/2024 18:39:06][rank 0][INFO][__main__] - [1m######################################################[0m
0: [29/10/2024 18:39:06][rank 0][INFO][__main__] - ########  Project:    gpr_project
0: [29/10/2024 18:39:06][rank 0][INFO][__main__] - ########  Session:    design_model
0: [29/10/2024 18:39:06][rank 0][INFO][__main__] - ########  Experiment: test_setup
0: [29/10/2024 18:39:06][rank 0][INFO][__main__] - save logs and checkpoints in: /work/dlclarge2/ferreira-symreg/ScalingSymbolicRegression/experiments/gpr_project/design_model/test_setup-000
0: [29/10/2024 18:39:06][rank 0][INFO][__main__] - [1m############### CONFIGURATION[0m
0: [29/10/2024 18:39:06][rank 0][INFO][__main__] - experiment: {'experiments_base_dir': '/work/dlclarge2/ferreira-symreg/ScalingSymbolicRegression/experiments', 'project_name': 'gpr_project', 'session_name': 'design_model', 'experiment_name': 'test_setup'}
0: [29/10/2024 18:39:06][rank 0][INFO][__main__] - train: {'seed': 1, 'clip_value': 1.0, 'val_interval': 500, 'log_interval': 100, 'log_param_interval': 500, 'save_interval': 10000, 'max_steps': 20000, 'max_epochs': None}
0: [29/10/2024 18:39:06][rank 0][INFO][__main__] - optim: {'optimizer': 'AdamW', 'lr': 0.0001, 'weight_decay': 0.1, 'betas': [0.9, 0.98], 'eps': 1e-09, 'normalization_regularization': False, 'bias_regularization': False, 'scheduler': {'num_warmup_steps': 400, 'num_training_steps': 20000, 'decay_factor': 0.01, 'schedule': 'cosine'}, 'cpr_config': {'kappa_init_param': 400, 'kappa_init_method': 'warm_start', 'reg_function': 'l2', 'kappa_update': 1.0}}
0: [29/10/2024 18:39:06][rank 0][INFO][__main__] - accelerate: {'mixed_precision': 'fp16'}
0: [29/10/2024 18:39:06][rank 0][INFO][__main__] - model: {'trg_vocab_size': 1, 'seq_vocab_size': 1, 'model_dim': 256, 'max_len': 400, 'num_head': 4, 'n_layers_enc': 4, 'n_layers_dec': 6, 'ff_factor': 4, 'activation': 'silu', 'glu': False, 'softmax_scale': True, 'pos_embedding': True, 'rel_pos_enc': False, 'add_unit_offset': False, 'rms_norm': False, 'resi_dropout': 0.1, 'attn_dropout': 0.1, 'ln_eps': 1e-05, 'use_bias': True, 'learn_ln': True, 'last_zero': False, 'initializer_range': 0.02}
0: [29/10/2024 18:39:06][rank 0][INFO][__main__] - dataloader: {'generator': {'num_variables': 2, 'max_terms': 4, 'num_realizations': 100, 'allowed_operations': ['+', '-', '*', '/', 'cos', 'log', 'sin', 'exp'], 'real_numbers_realizations': False, 'kmax': 5, 'keep_graph': False, 'keep_data': False, 'real_numbers_variables': False, 'max_powers': 1, 'seed': 1}, 'val_samples': 500, 'test_samples': 200, 'batch_size': 64, 'num_workers': 8}
0: [29/10/2024 18:39:06][rank 0][INFO][__main__] - [1m############### LOAD DATA on rank 0[0m
0: Traceback (most recent call last):
0:   File "/work/dlclarge2/ferreira-symreg/ScalingSymbolicRegression/train_gpr.py", line 336, in <module>
0:     main(config_dict)
0:   File "/work/dlclarge2/ferreira-symreg/ScalingSymbolicRegression/train_gpr.py", line 96, in main
0:     sympy_data = SymPySimpleDataModule(cfg, logger=logger, )
0:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
0:   File "/work/dlclarge2/ferreira-symreg/ScalingSymbolicRegression/gpr/data/loaders.py", line 60, in __init__
0:     self.real_const_decimal_places = self.config.generator.real_const_decimal_places
0:                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
0: AttributeError: 'SimpleNestedNamespace' object has no attribute 'real_const_decimal_places'
0: [2024-10-29 18:39:08,156] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 14242) of binary: /home/ferreira/.miniconda/envs/symreg/bin/python
0: Traceback (most recent call last):
0:   File "/home/ferreira/.miniconda/envs/symreg/bin/accelerate", line 8, in <module>
0:     sys.exit(main())
0:              ^^^^^^
0:   File "/home/ferreira/.miniconda/envs/symreg/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py", line 46, in main
0:     args.func(args)
0:   File "/home/ferreira/.miniconda/envs/symreg/lib/python3.11/site-packages/accelerate/commands/launch.py", line 1066, in launch_command
0:     multi_gpu_launcher(args)
0:   File "/home/ferreira/.miniconda/envs/symreg/lib/python3.11/site-packages/accelerate/commands/launch.py", line 711, in multi_gpu_launcher
0:     distrib_run.run(args)
0:   File "/home/ferreira/.miniconda/envs/symreg/lib/python3.11/site-packages/torch/distributed/run.py", line 803, in run
0:     elastic_launch(
0:   File "/home/ferreira/.miniconda/envs/symreg/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
0:     return launch_agent(self._config, self._entrypoint, list(args))
0:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
0:   File "/home/ferreira/.miniconda/envs/symreg/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
0:     raise ChildFailedError(
0: torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
0: ============================================================
0: /work/dlclarge2/ferreira-symreg/ScalingSymbolicRegression/train_gpr.py FAILED
0: ------------------------------------------------------------
0: Failures:
0:   <NO_OTHER_FAILURES>
0: ------------------------------------------------------------
0: Root Cause (first observed failure):
0: [0]:
0:   time      : 2024-10-29_18:39:08
0:   host      : dlcgpu01.rz.ki.privat
0:   rank      : 0 (local_rank: 0)
0:   exitcode  : 1 (pid: 14242)
0:   error_file: <N/A>
0:   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
0: ============================================================
srun: error: dlcgpu01: task 0: Exited with exit code 1
+ (( i++  ))
+ (( i<1 ))
