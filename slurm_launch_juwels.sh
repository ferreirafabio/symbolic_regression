#!/bin/bash -x
#SBATCH --nodes=1
#SBATCH --gres=gpu:4
## SBATCH --exclude=jwb[0067,0069,0637,0829,0832,0907,0921]
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=12
#SBATCH --job-name=llmGPw
#SBATCH -D .
#SBATCH --account=cstdl
#SBATCH --partition=develbooster
#SBATCH --threads-per-core=1
#SBATCH --time=2:00:00
#SBATCH --output=/p/scratch/laionize/franke5/experiments/output/mpi-out.%j
#SBATCH --error=/p/scratch/laionize/franke5/experiments/error/mpi-err.%j


CODE_DIR="/p/scratch/laionize/franke5/workspace/ScalingSymbolicRegression"

export SRUN_CPUS_PER_TASK=${SLURM_CPUS_PER_TASK}

export NCCL_IB_TIMEOUT=50
export UCX_RC_TIMEOUT=4s
export NCCL_IB_RETRY_CNT=10
export NCCL_SOCKET_IFNAME=ib0


export CUDA_VISIBLE_DEVICES="0,1,2,3"
# export CUDA_LAUNCH_BLOCKING=0

MASTER_ADDR=`scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1`
# Allow communication over InfiniBand cells.

export MASTER_ADDR="${MASTER_ADDR}i"

export MASTER_PORT=20073
export NUM_NODES=$SLURM_JOB_NUM_NODES
export GPUS_PER_NODE=4
export NUM_GPUS_PER_NODE=4
export NUM_GPUS=$((NUM_GPUS_PER_NODE*SLURM_NNODES))
# export NCCL_DEBUG=INFO

echo "INFO: number of nodes: $NUM_NODES"
echo "INFO: number of gpus per node: $NUM_GPUS_PER_NODE"
echo "INFO: number of gpus: $NUM_GPUS"
echo "INFO: number of nnudes: $SLURM_NNODES"


ACCELERATE_CONFIG_FILE="${CODE_DIR}/scripts/accelerate.yaml"

cat << EOT > $ACCELERATE_CONFIG_FILE
# WARNING: do not edit this file as this is an slurm-auto-generated file
compute_environment: LOCAL_MACHINE
debug: false
distributed_type: MULTI_GPU
main_process_ip: $MASTER_ADDR
main_process_port: $MASTER_PORT
main_training_function: main
num_machines: $SLURM_NNODES
num_processes: $NUM_GPUS
use_cpu: false
EOT


ml Stages/2024
ml CUDA/12
ml GCC/12.3.0
ml Python/3.11.3

echo "SLURM_PARTITION=$SLURM_NODELIST"

if echo "$SLURM_NODELIST" | grep -q "jrc"; then
    echo "JURECA Job"
    source /p/scratch/laionize/franke5/pt22r/bin/activate
else
    echo "JUWELS Job"
    source /p/scratch/laionize/franke5/pt22/bin/activate
fi

PYTHON_SCRIPT=/p/scratch/laionize/franke5/workspace/GPTworkbench/train_gpt_model.py

srun -lN1 -n1 -r 0 accelerate launch --config_file $ACCELERATE_CONFIG_FILE \
--rdzv_conf "rdzv_backend=c10d,rdzv_endpoint=$MASTER_ADDR:$MASTER_PORT" --main_process_ip $MASTER_ADDR \
--main_process_port $MASTER_PORT --machine_rank 0 $PYTHON_SCRIPT -c juwels_config.yaml $@
