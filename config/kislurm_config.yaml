experiment:
  experiments_base_dir: /home/frankej/experiments/symreg/
  project_name: gpr_project
  session_name: design_model
  experiment_name: test_setup
  inference_set: "valid" # or "test"


train:
  seed: 1
  clip_value: 1.0
  val_interval: 500
  log_interval: 100
  log_param_interval: 500
  save_interval: 10000
  max_steps: 20000
  max_epochs: null


optim:
  optimizer: AdamW
  lr: 0.0001
  weight_decay: 0.1
  betas:
    - 0.9
    - 0.98
  eps: 1.0e-09
  normalization_regularization: False
  bias_regularization: False
  scheduler:
    num_warmup_steps: 400 #${eval:0.01 * ${trainer.max_steps}}
    num_training_steps: ${train.max_steps}
    decay_factor: 0.01
    schedule: "cosine" # "cosine" or "linear"
  cpr_config:
    kappa_init_param: 400
    kappa_init_method: 'warm_start'
    reg_function: 'l2'
    kappa_update: 1.0


accelerate:
  mixed_precision: fp16


model:
    trg_vocab_size: 1
    seq_vocab_size: 1
    model_dim: 256
    max_len: 400
    num_head: 4
    n_layers_enc: 4
    n_layers_dec: 6
    ff_factor: 4
    activation: silu
    glu: false
    softmax_scale: True
    pos_embedding: True
    rel_pos_enc: False
    add_unit_offset: False
    rms_norm: False
    resi_dropout: 0.1
    attn_dropout: 0.1
    ln_eps: 1e-5
    use_bias: True
    learn_ln: True
    last_zero: False
    initializer_range: 0.02


dataloader:
    generator:
        num_variables: 2
        max_terms: 4
        num_realizations: 100
        allowed_operations: ["+", "-", "*", "/", "cos", "log", "sin", "exp"]
        real_numbers_realizations: False
        sample_interval: [-10, 10]
        keep_graph: False
        keep_data: False
        real_numbers_variables: False
        max_powers: 1
        seed: 1
    val_samples: 500
    test_samples: 200 # this is just a placeholder for the test set
    batch_size: 64
    num_workers: 8
